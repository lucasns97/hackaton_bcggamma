{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# some helpful imports from sklearndf\n",
    "from sklearndf.pipeline import RegressorPipelineDF\n",
    "from sklearndf.regression import RandomForestRegressorDF\n",
    "\n",
    "# relevant FACET imports\n",
    "from facet.data import Sample\n",
    "from facet.selection import LearnerRanker, LearnerGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINAN_PATH      = './../data/raw_data/SINAN_prep_05.csv'\n",
    "MUNICIPIOS_PATH = './../data/municipios_prep_05.csv'\n",
    "BOLSA_PATH = './../data/consolidada_bolsafamilia.csv'\n",
    "INEP_PATH = './../data/consolidada_inep.csv'\n",
    "ATLAS_PATH = './../data/atlas_desenvolvimento_humano_por_municipio.csv'\n",
    "OCUPACOES_PATH  = './../data/cbo_ocupacoes.csv'\n",
    "PNAD_PATH  = './../data/PNAD_consolidado.csv'\n",
    "MAPBOX_TOKEN    = 'pk.eyJ1IjoibHVjYXNuc2VxIiwiYSI6ImNrb241dHZ0cTBpd2MycW5yMGp2enFtMmkifQ.N6NJGlWhG-iYrIJMQ1MVVw'\n",
    "\n",
    "px.set_mapbox_access_token(MAPBOX_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios_df = pd.read_csv(MUNICIPIOS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ba734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(values):\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoded = encoder.fit_transform(values.reshape(-1, 1))\n",
    "    \n",
    "    return encoded, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(municipios_df, x='pop_2017', marginal=\"box\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ca3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = municipios_df[(municipios_df['pop_2017'] >= 10000) &  (municipios_df['pop_2017'] <= 500000)]\n",
    "fig = px.histogram(df, x='denun_relat_2017', marginal=\"box\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547bda8",
   "metadata": {},
   "source": [
    "### Pipeline de preparação dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e7760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_munic_nan_indexes(dataframe):\n",
    "    \n",
    "    munic_cols = []\n",
    "\n",
    "    for col in dataframe.columns:\n",
    "        if 'munic' in col:\n",
    "            munic_cols.append(col)\n",
    "            \n",
    "    for i, col in enumerate(munic_cols):\n",
    "        \n",
    "        if i == 0:\n",
    "            df = dataframe[dataframe[col].notna()]\n",
    "        else:\n",
    "            df = df[df[col].notna()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171eba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_pipeline(dataframe, years, train_size = 0.7, filter_pop = True):\n",
    "    '''\n",
    "    Retorna X_df_train, Y_df_train, X_df_test e Y_df_test\n",
    "    '''\n",
    "    \n",
    "    values_df = dataframe.set_index('id')\n",
    "    \n",
    "    # Removendo valores NaN do MUNIC\n",
    "    values_df = remove_munic_nan_indexes(values_df)\n",
    "    \n",
    "    # Colunas do munic\n",
    "    munic_cols = []\n",
    "\n",
    "    for col in municipios_df.columns:\n",
    "        if 'munic' in col:\n",
    "            munic_cols.append(col)\n",
    "            \n",
    "    for col in ['munic_y13_a4', 'munic_y13_a21', 'munic_y13_a233', 'munic_y13_a240']:\n",
    "        munic_cols.remove(col)\n",
    "    \n",
    "    # Features\n",
    "    feature_columns = ['regiao', 'uf'] + munic_cols\n",
    "    feature_columns = ['regiao', 'uf']\n",
    "    \n",
    "    encodeds, encoders = {}, {}\n",
    "    for column in feature_columns:\n",
    "\n",
    "        encodeds[column], encoders[column] = get_encoder(values_df[column].values)\n",
    "        values_df[column] = encodeds[column]\n",
    "        \n",
    "    # Estáticas\n",
    "    estatic_columns = ['latitude', 'pnad_espvida', 'pnad_rdpc','pnad_t_analf25m','pnad_t_freq15a17',\n",
    "                       'pnad_t_freq5a6','pnad_t_freq6a14','pnad_anosest','pnad_mort1','pnad_razdep','pnad_gini',\n",
    "                       'pnad_prentrab','pnad_pind','pnad_rmpob'] + feature_columns\n",
    "    \n",
    "    # Variáveis\n",
    "    variable_prefix = ['pop', 'renda', 'share', 'percentual', 'denun_relat']\n",
    "    \n",
    "    variable_prefix_skip = ['faixa_60_120', 'faixa_0_13', 'faixa_14_17', 'cbo_grupo_profissiona', 'ef i comp', 'ef ii incom',\n",
    "                            'membros superior', 'membros das forças', 'trabalho infantil', 'sit_conjug_solteir', 'ssor_cuidador',\n",
    "                            'ssor_irmão', 'motiv_defici', 'media_median', 'sexo_i', 'violence_legal', 'trabalhadores em serviços']\n",
    "    \n",
    "    year_columns = []\n",
    "    for col in values_df.columns:\n",
    "        skip = False\n",
    "        for skip_prefix in variable_prefix_skip:\n",
    "            if skip_prefix in col:\n",
    "                skip = True\n",
    "                break\n",
    "        if not skip:\n",
    "            for prefix in variable_prefix:\n",
    "                if prefix in col:\n",
    "                    year_columns.append(col)\n",
    "                    \n",
    "    # Removendo sufixo de ano \"_year\"\n",
    "    renamed_year_columns_map = {}\n",
    "    for col in year_columns:\n",
    "        renamed_year_columns_map[col] = '_'.join(col.split('_')[:-1])\n",
    "        \n",
    "    keep_columns = year_columns + estatic_columns\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    min_population = 10000\n",
    "    max_population = 500000\n",
    "    \n",
    "    for year in years:\n",
    "        \n",
    "        # Selecionando intervalo de população\n",
    "        \n",
    "        if filter_pop:\n",
    "            temp_df = values_df[(values_df[f'pop_{year}'] >= min_population) & (values_df[f'pop_{year}'] <= max_population)]\n",
    "        else:\n",
    "            temp_df = values_df.copy()\n",
    "        \n",
    "        year_df = pd.DataFrame(index = temp_df.index)\n",
    "        for col in estatic_columns:\n",
    "            year_df[col] = temp_df[col]\n",
    "            \n",
    "        for col in year_columns:\n",
    "            if str(year) in col:\n",
    "                year_df[col] = temp_df[col]\n",
    "                \n",
    "        year_df = year_df.rename(renamed_year_columns_map, axis=1)\n",
    "        \n",
    "        year_df = year_df.rename(lambda x : f'{x}_{year}', axis=0)\n",
    "        \n",
    "        year_df = year_df.fillna(-1)\n",
    "        \n",
    "        df = pd.concat((df, year_df))\n",
    "    \n",
    "    X_df = df.drop(f'denun_relat', axis=1)\n",
    "    Y_df = df['denun_relat']\n",
    "    \n",
    "    ####### tirar uma amostra das colunas\n",
    "    \n",
    "    # Separando df em train/test\n",
    "    train_indexes = list(np.random.choice(X_df.index, int(len(X_df)*train_size), replace = False))\n",
    "    test_indexes  = []\n",
    "    \n",
    "    for index in X_df.index:\n",
    "        if index not in train_indexes:\n",
    "            test_indexes.append(index)\n",
    "    \n",
    "    X_df_train = X_df.drop(test_indexes, axis=0)\n",
    "    Y_df_train = Y_df.drop(test_indexes, axis=0)\n",
    "    X_df_test  = X_df.drop(train_indexes, axis=0)\n",
    "    Y_df_test  = Y_df.drop(train_indexes, axis=0)\n",
    "    \n",
    "    return X_df_train, Y_df_train, X_df_test, Y_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8679ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_result(X_df, Y_df, regressor, original_df, years):\n",
    "    \n",
    "    X_values = X_df.values\n",
    "    Y_values = Y_df.values.reshape(-1, 1)\n",
    "    \n",
    "    predictions_df = pd.DataFrame()\n",
    "    \n",
    "    predictions_df['prediction'] = regressor.predict(X_values).reshape(-1,)\n",
    "    predictions_df['real']       = Y_values.reshape(-1,)\n",
    "\n",
    "    \n",
    "    predictions_df['abs_diff']   = np.abs(predictions_df['prediction'] - predictions_df['real'])\n",
    "    predictions_df['diff']       = predictions_df['prediction'] - predictions_df['real']\n",
    "    predictions_df['sqr_diff']   = (predictions_df['prediction'] - predictions_df['real'])**2\n",
    "    \n",
    "    variables           = ['nome', 'uf', 'regiao', 'pop', 'year']\n",
    "    variables_values    = {}\n",
    "    \n",
    "    original_df_indexed = original_df.set_index('id')\n",
    "    \n",
    "    for variable in variables:\n",
    "        variables_values[variable] = []\n",
    "        \n",
    "    for index in X_df.index:\n",
    "        \n",
    "        index_parts = index.split('_')\n",
    "        mun_id, year = int(index_parts[0]), int(index_parts[1])\n",
    "\n",
    "        mun_data = original_df_indexed.loc[mun_id]\n",
    "        \n",
    "        for variable in variables:\n",
    "            \n",
    "            if variable == 'pop':\n",
    "                variables_values[variable].append(mun_data[f'pop_{year}'])\n",
    "            elif variable == 'year':\n",
    "                variables_values[variable].append(year)\n",
    "            else:\n",
    "                variables_values[variable].append(mun_data[variable])\n",
    "    \n",
    "    for variable in variables:\n",
    "        predictions_df[variable] = variables_values[variable]\n",
    "        \n",
    "    score = regressor.score(X_values, Y_values)\n",
    "    name  = str(regressor).split('()')[0]\n",
    "    \n",
    "    title = f'Regressor: {name} | score: {round(score, 5)}'\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    size   = scaler.fit_transform(predictions_df['year'].values.reshape(-1, 1)).reshape(-1)\n",
    "    col_year = predictions_df['year'].apply(lambda x : f'y_{x}')\n",
    "\n",
    "    fig = px.scatter(predictions_df, x='prediction', y='real', color='diff', size=size, size_max=7,\n",
    "                     hover_data=variables + ['abs_diff', 'diff', 'sqr_diff'], title=title)\n",
    "    \n",
    "    max_val = np.max(predictions_df['prediction'].values)\n",
    "    min_val = np.min(predictions_df['prediction'].values)\n",
    "    \n",
    "    fig.add_trace(go.Line(x=np.linspace(min_val*0.9,max_val*1.1), y=np.linspace(min_val*0.9,max_val*1.1)))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896b32c",
   "metadata": {},
   "source": [
    "### Aplicando alguns regressores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5b731",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c50f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "years = [2013, 2014, 2015, 2016, 2017]\n",
    "\n",
    "X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, years, train_size = 0.7, filter_pop = False)\n",
    "\n",
    "X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "lr_regressor = LinearRegression()\n",
    "\n",
    "lr_regressor = lr_regressor.fit(X_values_train, Y_value_train)\n",
    "score     = lr_regressor.score(X_df_test, Y_df_test)\n",
    "\n",
    "print(f'Train Size: {round(100*len(X_df_train)/(len(municipios_df)*len(years)), 2)}% | {len(X_df_train)}/{len(municipios_df)*len(years)}')\n",
    "print('Score:', round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e30be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae629d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df_test, Y_df_test, lr_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e37d46f",
   "metadata": {},
   "source": [
    "### Polynomial Features (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# years = [2013, 2014, 2015, 2016, 2017]\n",
    "\n",
    "# X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, years, train_size = 0.7)\n",
    "\n",
    "# X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "# X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "# dim = 3\n",
    "# poly = PolynomialFeatures(dim)\n",
    "\n",
    "# X_values_train = poly.fit_transform(X_values_train)\n",
    "# X_values_test  = poly.transform(X_values_test)\n",
    "\n",
    "# lr_poly_regressor = LinearRegression()\n",
    "\n",
    "# lr_poly_regressor = lr_poly_regressor.fit(X_values_train, Y_value_train)\n",
    "# score             = lr_poly_regressor.score(X_values_test, Y_df_test)\n",
    "\n",
    "# print(f'Train Size: {round(100*len(X_df_train)/(len(municipios_df)*len(years)), 2)}% | {len(X_df_train)}/{len(municipios_df)*len(years)}')\n",
    "# print('Score:', round(score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367e906",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85fc14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "years = [2013, 2014, 2015, 2016, 2017]\n",
    "\n",
    "X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, years, train_size = 0.7, filter_pop = False)\n",
    "\n",
    "X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "rf_regressor = rf_regressor.fit(X_values_train, Y_value_train)\n",
    "score     = rf_regressor.score(X_df_test, Y_df_test)\n",
    "\n",
    "print(f'Train Size: {round(100*len(X_df_train)/(len(municipios_df)*len(years)), 2)}% | {len(X_df_train)}/{len(municipios_df)*len(years)}')\n",
    "print('Score:', round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df_test, Y_df_test, rf_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8340be",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cedf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "years = [2013, 2014, 2015, 2016, 2017]\n",
    "\n",
    "X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, years, train_size = 0.7, filter_pop = False)\n",
    "\n",
    "X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "xg_regressor = GradientBoostingRegressor()\n",
    "\n",
    "xg_regressor = xg_regressor.fit(X_values_train, Y_value_train)\n",
    "score        = xg_regressor.score(X_df_test, Y_df_test)\n",
    "\n",
    "print(f'Train Size: {round(100*len(X_df_train)/(len(municipios_df)*len(years)), 2)}% | {len(X_df_train)}/{len(municipios_df)*len(years)}')\n",
    "print('Score:', round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430cc7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df_test, Y_df_test, xg_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62061255",
   "metadata": {},
   "source": [
    "#### Avaliando Capitais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2013, 2014]\n",
    "\n",
    "capitals = ['Rio Branco','Maceió','Macapá','Manaus','Salvador','Fortaleza','Brasília','Vitória',\n",
    "            'Goiânia','São Luís','Cuiabá','Campo Grande','Belo Horizonte','Belém','João Pessoa',\n",
    "            'Curitiba','Recife','Teresina','Rio de Janeiro','Natal','Porto Alegre','Porto Velho',\n",
    "            'Boa Vista','Florianópolis','São Paulo','Aracaju','Palmas']\n",
    "\n",
    "mun_data = municipios_df[municipios_df['nome'].isin(capitals)]\n",
    "\n",
    "X_df, Y_df, _, _ = train_test_data_pipeline(mun_data, years, train_size = 1, filter_pop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4294d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df, Y_df, lr_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78539ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df, Y_df, rf_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6722c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df, Y_df, xg_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87495f96",
   "metadata": {},
   "source": [
    "#### Avaliando base toda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b9784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, Y_df, _, _ = train_test_data_pipeline(municipios_df, years, train_size = 1, filter_pop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1edcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df, Y_df, lr_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6315707",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df, Y_df, rf_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df, Y_df, xg_regressor, municipios_df, years)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2599a8f",
   "metadata": {},
   "source": [
    "#### Colunas usadas no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2410ea6",
   "metadata": {},
   "source": [
    "### Facet Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2013,2015,2017]\n",
    "\n",
    "X_df_train, Y_df_train, _, _ = train_test_data_pipeline(municipios_df, years, train_size = 1)\n",
    "\n",
    "df = X_df_train.copy()\n",
    "df['denun_relat'] = Y_df_train.values\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46017cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create FACET sample object\n",
    "df_sample = Sample(observations=df, target_name=\"denun_relat\")\n",
    "\n",
    "# create a (trivial) pipeline for a random forest regressor\n",
    "rnd_forest_reg = RegressorPipelineDF(\n",
    "    regressor=RandomForestRegressorDF(n_estimators=200, random_state=42)\n",
    ")\n",
    "\n",
    "# define grid of models which are \"competing\" against each other\n",
    "rnd_forest_grid = [\n",
    "    LearnerGrid(\n",
    "        pipeline=rnd_forest_reg,\n",
    "        learner_parameters={\n",
    "            \"min_samples_leaf\": [8, 11],\n",
    "            \"max_depth\": [10, 12],\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "\n",
    "# create repeated k-fold CV iterator\n",
    "rkf_cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "# rank your candidate models by performance (default is mean CV score - 2*SD)\n",
    "ranker = LearnerRanker(\n",
    "    grids=rnd_forest_grid, cv=rkf_cv, n_jobs=-3\n",
    ").fit(sample=df_sample)\n",
    "\n",
    "# get summary report\n",
    "ranker.summary_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model inspector\n",
    "from facet.inspection import LearnerInspector\n",
    "inspector = LearnerInspector(n_jobs=-3)\n",
    "inspector.fit(crossfit=ranker.best_model_crossfit_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10919da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise synergy as a matrix\n",
    "from pytools.viz.matrix import MatrixDrawer\n",
    "synergy_matrix = inspector.feature_synergy_matrix()\n",
    "px.imshow(synergy_matrix, width = 2500, height = 2500, title = 'Sinergy Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise redundancy as a matrix\n",
    "redundancy_matrix = inspector.feature_redundancy_matrix()\n",
    "px.imshow(redundancy_matrix, width = 2500, height = 2500, title = 'Redudancy Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef755cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise redundancy using a dendrogram\n",
    "from pytools.viz.dendrogram import DendrogramDrawer\n",
    "import matplotlib.pyplot as plt\n",
    "redundancy = inspector.feature_redundancy_linkage()\n",
    "\n",
    "plt.figure(figsize=(14,40))\n",
    "DendrogramDrawer().draw(data=redundancy, title=\"Redundancy Dendrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c06e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['denun_relat_2016', 'denun_maioridade_relat_2016', 'denun_relacao_2016', \n",
    "                'denun_relat_2015', 'denun_maioridade_relat_2015', 'denun_relacao_2015',\n",
    "                'denun_count_2015', 'denun_relat_2014', 'denun_relat_2013', 'denun_count_2014',\n",
    "                'renda_media_sum_2013', 'renda_media_sum_2016', 'latitude', 'regiao', \n",
    "                'share_agua_canalizada_2013', 'share_agua_canalizada_2016', 'renda_media_median_2013', \n",
    "                'renda_media_median_2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACET imports\n",
    "from facet.validation import BootstrapCV\n",
    "from facet.crossfit import LearnerCrossfit\n",
    "from facet.simulation import UnivariateUpliftSimulator\n",
    "from facet.data.partition import ContinuousRangePartitioner\n",
    "from facet.simulation.viz import SimulationDrawer\n",
    "\n",
    "# create bootstrap CV iterator\n",
    "bscv = BootstrapCV(n_splits=1000, random_state=42)\n",
    "\n",
    "# create a bootstrap CV crossfit for simulation using best model\n",
    "boot_crossfit = LearnerCrossfit(\n",
    "    pipeline=ranker.best_model_,\n",
    "    cv=bscv,\n",
    "    n_jobs=-3,\n",
    "    verbose=False,\n",
    ").fit(sample=df_sample)\n",
    "\n",
    "SIM_FEAT = \"denun_relat_2016\"\n",
    "simulator = UnivariateUpliftSimulator(crossfit=boot_crossfit, n_jobs=-3)\n",
    "\n",
    "# split the simulation range into equal sized partitions\n",
    "partitioner = ContinuousRangePartitioner()\n",
    "\n",
    "# run the simulation\n",
    "simulation = simulator.simulate_feature(feature_name=SIM_FEAT, partitioner=partitioner)\n",
    "\n",
    "# visualise results\n",
    "plt.figure(figsize=(14,12))\n",
    "SimulationDrawer().draw(data=simulation, title=SIM_FEAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605c1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
