{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINAN_PATH      = './../data/raw_data/SINAN_prep_05.csv'\n",
    "MUNICIPIOS_PATH = './../data/municipios_prep_02.csv'\n",
    "BOLSA_PATH = './../data/consolidada_bolsafamilia.csv'\n",
    "INEP_PATH = './../data/consolidada_inep.csv'\n",
    "ATLAS_PATH = './../data/atlas_desenvolvimento_humano_por_municipio.csv'\n",
    "OCUPACOES_PATH  = './../data/cbo_ocupacoes.csv'\n",
    "MAPBOX_TOKEN    = 'pk.eyJ1IjoibHVjYXNuc2VxIiwiYSI6ImNrb241dHZ0cTBpd2MycW5yMGp2enFtMmkifQ.N6NJGlWhG-iYrIJMQ1MVVw'\n",
    "\n",
    "px.set_mapbox_access_token(MAPBOX_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edbe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios_df = pd.read_csv(MUNICIPIOS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ba734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(values):\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    encoded = encoder.fit_transform(values.reshape(-1, 1))\n",
    "    \n",
    "    return encoded, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b49e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(municipios_df, x='pop_2017', marginal=\"box\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58145fa",
   "metadata": {},
   "source": [
    "### Pipeline de preparação dos dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af849998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_pipeline(dataframe, train_size = 0.7):\n",
    "    '''\n",
    "    Retorna X_df_train, Y_df_train, X_df_test e Y_df_test\n",
    "    '''\n",
    "    \n",
    "    values_df = dataframe.set_index('id')\n",
    "    \n",
    "    # Removemdo colunas indesejadas\n",
    "    remove_cols = ['id', 'nome', 'uf_nome', 'uf_id', 'sinan_id', 'cluster_id']\n",
    "    \n",
    "    for col in remove_cols:\n",
    "        \n",
    "        try:\n",
    "            values_df = values_df.drop(col, axis=1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # Selecionando intervalo de população\n",
    "    \n",
    "    min_population = 10000\n",
    "    max_population = 500000\n",
    "    values_df      = values_df[values_df['pop_2017'] > min_population]\n",
    "    values_df      = values_df[values_df['pop_2017'] < max_population]\n",
    "    \n",
    "    # Encoders em algumas colunas\n",
    "    \n",
    "    encoders = {}\n",
    "    encodeds = {}\n",
    "    feature_columns = ['uf', 'regiao']\n",
    "\n",
    "    for column in feature_columns:\n",
    "\n",
    "        encodeds[column], encoders[column] = get_encoder(values_df[column].values)\n",
    "        values_df[column] = encodeds[column]\n",
    "        \n",
    "    # Fillna\n",
    "    values_df = values_df.fillna(-1)\n",
    "    \n",
    "    # Removendo outras colunas excessivas\n",
    "    \n",
    "    remove_cols = []\n",
    "    for col in values_df.columns:\n",
    "        if 'icg' in col or 'comodos' in col:\n",
    "            remove_cols.append(col)\n",
    "    \n",
    "    values_df = values_df.drop(remove_cols, axis=1)\n",
    "    \n",
    "    # Removendo colunas de 2017 e dividindo entre X_df e Y_df\n",
    "    \n",
    "    remove_cols = []\n",
    "    for col in values_df.columns:\n",
    "        if '2017' in col:\n",
    "            remove_cols.append(col)\n",
    "    \n",
    "    X_df = values_df.drop(remove_cols, axis=1)\n",
    "    Y_df = values_df['denun_relat_2017']\n",
    "    \n",
    "    # Separando df em train/test\n",
    "    train_indexes = list(np.random.choice(X_df.index, int(len(X_df)*train_size), replace = False))\n",
    "    test_indexes  = []\n",
    "    \n",
    "    for index in X_df.index:\n",
    "        if index not in train_indexes:\n",
    "            test_indexes.append(index)\n",
    "    \n",
    "    X_df_train = X_df.drop(test_indexes, axis=0)\n",
    "    Y_df_train = Y_df.drop(test_indexes, axis=0)\n",
    "    X_df_test  = X_df.drop(train_indexes, axis=0)\n",
    "    Y_df_test  = Y_df.drop(train_indexes, axis=0)\n",
    "    \n",
    "    return X_df_train, Y_df_train, X_df_test, Y_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d59a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_result(X_df, Y_df, regressor, original_df):\n",
    "    \n",
    "    X_values = X_df.values\n",
    "    Y_values = Y_df.values.reshape(-1, 1)\n",
    "    \n",
    "    predictions_df = pd.DataFrame()\n",
    "    \n",
    "    predictions_df['prediction'] = regressor.predict(X_values).reshape(-1,)\n",
    "    predictions_df['real']       = Y_values.reshape(-1,)\n",
    "\n",
    "    \n",
    "    predictions_df['abs_diff']   = np.abs(predictions_df['prediction'] - predictions_df['real'])\n",
    "    predictions_df['diff']       = predictions_df['prediction'] - predictions_df['real']\n",
    "    predictions_df['sqr_diff']   = (predictions_df['prediction'] - predictions_df['real'])**2\n",
    "    \n",
    "    variables           = ['nome', 'uf', 'regiao', 'pop_2016']\n",
    "    variables_values    = {}\n",
    "    original_df_indexed = original_df.set_index('id')\n",
    "    \n",
    "    for variable in variables:\n",
    "        variables_values[variable] = []\n",
    "        \n",
    "    for mun_id in X_df.index:\n",
    "\n",
    "        mun_data = original_df_indexed.loc[mun_id]\n",
    "        \n",
    "        for variable in variables:\n",
    "            variables_values[variable].append(mun_data[variable])\n",
    "    \n",
    "    for variable in variables:\n",
    "        predictions_df[variable] = variables_values[variable]\n",
    "        \n",
    "    score = regressor.score(X_values, Y_values)\n",
    "    name  = str(regressor).split('()')[0]\n",
    "    \n",
    "    title = f'Regressor: {name} | score: {round(score, 5)}'\n",
    "    \n",
    "\n",
    "    fig = px.scatter(predictions_df, x='prediction', y='real', color=\"abs_diff\", \n",
    "                     hover_data=variables + ['abs_diff', 'diff', 'sqr_diff'], title=title)\n",
    "    \n",
    "    max_val = np.max(predictions_df['prediction'].values)\n",
    "    min_val = np.min(predictions_df['prediction'].values)\n",
    "    \n",
    "    fig.add_trace(go.Line(x=np.linspace(min_val*0.9,max_val*1.1), y=np.linspace(min_val*0.9,max_val*1.1)))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b895f",
   "metadata": {},
   "source": [
    "### Aplicando alguns regressores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d526e9",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, train_size = 0.7)\n",
    "\n",
    "X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "\n",
    "regressor = regressor.fit(X_values_train, Y_value_train)\n",
    "score     = regressor.score(X_df_test, Y_df_test)\n",
    "\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df_test, Y_df_test, regressor, municipios_df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7614d60",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, train_size = 0.7)\n",
    "\n",
    "X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "regressor = regressor.fit(X_values_train, Y_value_train)\n",
    "score     = regressor.score(X_df_test, Y_df_test)\n",
    "\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266971b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df_test, Y_df_test, regressor, municipios_df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e189a9a",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d62b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_df_train, Y_df_train, X_df_test, Y_df_test = train_test_data_pipeline(municipios_df, train_size = 0.7)\n",
    "\n",
    "X_values_train, Y_value_train = X_df_train.values, Y_df_train.values.reshape(-1,)\n",
    "X_values_test, Y_values_test  = X_df_test.values, Y_df_test.values.reshape(-1,)\n",
    "\n",
    "regressor = GradientBoostingRegressor()\n",
    "\n",
    "regressor = regressor.fit(X_values_train, Y_value_train)\n",
    "score     = regressor.score(X_df_test, Y_df_test)\n",
    "\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_train_result(X_df_test, Y_df_test, regressor, municipios_df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab726ab",
   "metadata": {},
   "source": [
    "#### Avaliando Capitais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "capitals = ['Rio Branco','Maceió','Macapá','Manaus','Salvador','Fortaleza','Brasília','Vitória',\n",
    "            'Goiânia','São Luís','Cuiabá','Campo Grande','Belo Horizonte','Belém','João Pessoa',\n",
    "            'Curitiba','Recife','Teresina','Rio de Janeiro','Natal','Porto Alegre','Porto Velho',\n",
    "            'Boa Vista','Florianópolis','São Paulo','Aracaju','Palmas']\n",
    "\n",
    "mun_data = municipios_df[municipios_df['nome'].isin(capitals)]\n",
    "\n",
    "X_df, Y_df, _, _ = train_test_data_pipeline(mun_data, train_size = 1)\n",
    "\n",
    "fig = visualize_train_result(X_df, Y_df, regressor, municipios_df)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4118c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
